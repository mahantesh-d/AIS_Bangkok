--10.138.32.25 - GTM Master
--10.138.32.27 - GTM Slave
--10.138.32.232 - Coord1 Proxy1
--10.138.32.233 - Coord2 Proxy2
--10.138.32.80 - Master Data1
--10.138.32.81 - Master Data2
--10.138.32.26 - Slave Data1
--10.138.32.79 - Slave Data2

Starting the gtm manually
gtm -D /opt/damocles/data/DATA/pgxl/nodes/gtm
gtm -D /opt/damocles/data/DATA/pgxl/nodes/gtm_slv
gtm_proxy -D /opt/damocles/data/DATA/pgxl/nodes/gtm_pxy.1

Starting the Coordinator manually
/usr/local/pgsql/bin/postgres --coordinator -D /opt/damocles/data/DATA/pgxl/nodes/coord_master.1 -i
/usr/local/pgsql/bin/postgres --datanode -D /opt/damocles/data/DATA/pgxl/nodes/dn_master.1 -i


Adding nodes
pgxc_ctl

ADD gtm
add gtm master gtm <ip> <port> <dataDir>
add gtm master gtm 10.138.32.25 20001 $dataDirRoot/gtm

ADD COORDINATORS
PGXC# add coordinator master <nodename> <nodeip> <nodeport> <nodepoolerport> <nodedatadir> extraconfig extrapghbaconfig 
PGXC# add coordinator master coord2 localhost 30002 30012 $dataDirRoot/coord_master.2 none none

ADD GTM Slave and Proxy
add gtm slave gtm_slv 10.138.32.27 9090 /opt/damocles/data/DATA/pgxl/nodes/gtm_slv
add gtm_proxy gtm_proxy 10.138.32.27 7070 /opt/damocles/data/DATA/pgxl/nodes/gtm_proxy

ADD DATANODE
PGXC# add datanode master <nodename> <nodeip> <nodeport> <nodepoolerport> <nodedatadir> WALdir extraconfig extrapghbaconfig
PGXC# add datanode master dn3 localhost 40003 40013 $dataDirRoot/dn_master.3 none none none
Note that during cluster reconfiguration, all outstanding transactions are aborted and sessions are reset.
Once DATANODE is added
<database_name># ALTER TABLE <tablename> ADD NODE (<node_name>);
Above query will be hash distrubed on <node_name> node

ADD DATANODE Slave
PGXC# add datanode slave <node_name> <nodeip> <node_port> <nodepoolerport> <nodedatadir> <WALArchdir> <nodearchlogdir>
PGXC# add datanode slave dn1 localhost 40101 40111 $dataDirRoot/dn_slave.1 none $dataDirRoot/datanode_archlog.1 
add datanode slave datanode_1 10.138.32.26 40101 40111 /opt/damocles/data/DATA/pgxl/nodes/dn_slave.1 none /opt/damocles/data/DATA/pgxl/nodes/datanode_archlog.1


EXECUTE DIRECT ON(<master_data_node_name>) 'SELECT client_hostname, state, sync_state FROM pg_stat_replication';
this will sync the data from master data node to slave node

When master datanode fails run this command to switch to the slave
fail over, if datanode fails
pgxc_ctl
PGXC# failover datanode <node_name>
PGXC# failover datanode dn1

this will make datanode slave as master of that particular node_host

Removing the nodes
pgxc_ctl
PGXC# remove coordinator master/datanode master <node_name> clean
PGXC# remove coordinator master coord3 clean
Query to see the nodes
SELECT * FROM pgxc_node;
node_name  | node_type | node_port |   node_host   | nodeis_primary | nodeis_preferred |   node_id
------------+-----------+-----------+---------------+----------------+------------------+-------------
 coord1     | C         |     30001 | 10.138.32.212 | f              | f                |  1885696643
 coord2     | C         |     30002 | 10.138.32.213 | f              | f                | -1197102633
 coord3     | C         |     30003 | 10.138.32.214 | f              | f                |  1638403545
 datanode_1 | D         |     40001 | 10.138.32.212 | t              | f                |  -675012441
 datanode_2 | D         |     40002 | 10.138.32.213 | f              | t                | -1047623914
 datanode_3 | D         |     40003 | 10.138.32.214 | f              | f                |  1787525382

all_trade#ALTER TABLE <tablename> ADD NODE (dn3);

SELECT xc_node_id, count(*) FROM address GROUP BY xc_node_id;
 
--EXECUTE DIRECT ON (coord2) 'CREATE NODE coord1 WITH (TYPE=''coordinator'', HOST=''10.138.32.232'', PORT=30001)';

--EXECUTE DIRECT ON (coord2) 'CREATE NODE coord2 WITH (TYPE=''coordinator'', HOST=''10.138.32.233'', PORT=30002)';

--EXECUTE DIRECT ON (coord2) 'ALTER NODE datanode_1 WITH (TYPE=''datanode'', HOST=''10.138.32.80'', PORT=40001, PRIMARY)';

--EXECUTE DIRECT ON (coord2) 'CREATE NODE datanode_2 WITH (TYPE=''datanode'', HOST=''10.138.32.81'', PORT=40002)';

--EXECUTE DIRECT ON (coord2) 'SELECT pgxc_pool_reload()';

--EXECUTE DIRECT ON (datanode_2) 'CREATE NODE coord1 WITH (TYPE=''coordinator'', HOST=''10.138.32.232'', PORT=30001)';

--EXECUTE DIRECT ON (datanode_2) 'CREATE NODE coord2 WITH (TYPE=''coordinator'', HOST=''10.138.32.233'', PORT=30002)';

--EXECUTE DIRECT ON (datanode_2) 'CREATE NODE datanode_1 WITH (TYPE=''datanode'', HOST=''10.138.32.80'', PORT=40001, PRIMARY)';

--EXECUTE DIRECT ON (datanode_2) 'ALTER NODE datanode_2 WITH (TYPE=''datanode'', HOST=''10.138.32.81'', PORT=40002-----99999-++)';

--EXECUTE DIRECT ON (datanode_2) 'SELECT pgxc_pool_reload()';

CREATE NODE coord1 WITH (TYPE='coordinator', HOST='10.138.32.232', PORT=30001);

CREATE NODE coord2 WITH (TYPE='coordinator', HOST='10.138.32.233', PORT=30002);

CREATE node datanode_1 WITH (TYPE='datanode', HOST='10.138.32.80', PORT=40001, PRIMARY);

CREATE NODE datanode_2 WITH (TYPE='datanode', HOST='10.138.32.81', PORT=40002);

SELECT pgxc_pool_reload();

test=# CREATE TABLE disttab(col1 int, col2 int, col3 text) DISTRIBUTE BY HASH(col1);
CREATE TABLE
test=# \d+ disttab
                        Table "public.disttab"
 Column |  Type   | Modifiers | Storage  | Stats target | Description
--------+---------+-----------+----------+--------------+-------------
 col1   | integer |           | plain    |              |
 col2   | integer |           | plain    |              |
 col3   | text    |           | extended |              |
Distribute By: HASH(col1)
Location Nodes: ALL DATANODES

test=# CREATE TABLE repltab (col1 int, col2 int) DISTRIBUTE BY
test-# REPLICATION;
CREATE TABLE
test=#
test=# \d+ repltab
                       Table "public.repltab"
 Column |  Type   | Modifiers | Storage | Stats target | Description
--------+---------+-----------+---------+--------------+-------------
 col1   | integer |           | plain   |              |
 col2   | integer |           | plain   |              |
Distribute By: REPLICATION
Location Nodes: ALL DATANODES

test=# INSERT INTO disttab SELECT generate_series(1,100), generate_series(101, 200), 'foo';
INSERT 0 100
test=# INSERT INTO repltab SELECT generate_series(1,100), generate_series(101, 200);
INSERT 0 100
test=# SELECT count(*) FROM disttab;
 count
-------
   100
(1 row)

test=# SELECT xc_node_id, count(*) FROM disttab GROUP BY xc_node_id;
 xc_node_id  | count
-------------+-------
  -675012441 |    42
 -1047623914 |    58
(2 rows)

test=# SELECT xc_node_id, count(*) FROM disttab GROUP BY xc_node_id;
 xc_node_id  | count
-------------+-------
  -675012441 |    42
 -1047623914 |    58
(2 rows)

test=# SELECT xc_node_id, count(*) FROM repltab GROUP BY xc_node_id;
 xc_node_id  | count
-------------+-------
 -1047623914 |   100
(1 row)

test=#
test=# \d
          List of relations
 Schema |  Name   | Type  |   Owner
--------+---------+-------+-----------
 public | disttab | table | serveradm
 public | repltab | table | serveradm
(2 rows)

test=# \d+ disttab
                        Table "public.disttab"
 Column |  Type   | Modifiers | Storage  | Stats target | Description
--------+---------+-----------+----------+--------------+-------------
 col1   | integer |           | plain    |              |
 col2   | integer |           | plain    |              |
 col3   | text    |           | extended |              |
Distribute By: HASH(col1)
Location Nodes: ALL DATANODES

test=# \d+ repltab
                       Table "public.repltab"
 Column |  Type   | Modifiers | Storage | Stats target | Description
--------+---------+-----------+---------+--------------+-------------
 col1   | integer |           | plain   |              |
 col2   | integer |           | plain   |              |
Distribute By: REPLICATION
Location Nodes: ALL DATANODES

test=# SELECT xc_node_id, count(*) FROM disttab GROUP BY xc_node_id;
 xc_node_id  | count
-------------+-------
  -675012441 |    42
 -1047623914 |    58
(2 rows)

test=# SELECT xc_node_id, count(*) FROM repltab GROUP BY xc_node_id;
 xc_node_id  | count
-------------+-------
 -1047623914 |   100
(1 row)

test=# SELECT * FROM pgxc_node;
 node_name  | node_type | node_port |   node_host   | nodeis_primary | nodeis_preferred |   node_id
------------+-----------+-----------+---------------+----------------+------------------+-------------
 coord1     | C         |     30001 | 10.138.32.232 | f              | f                |  1885696643
 coord2     | C         |     30002 | 10.138.32.233 | f              | f                | -1197102633
 datanode_1 | D         |     40001 | 10.138.32.80  | t              | f                |  -675012441
 datanode_2 | D         |     40002 | 10.138.32.81  | f              | f                | -1047623914
(4 rows)


 PGXC# failover datanode datanode_2
 
 test=# SELECT * FROM pgxc_node;
 node_name  | node_type | node_port |   node_host   | nodeis_primary | nodeis_preferred |   node_id
------------+-----------+-----------+---------------+----------------+------------------+-------------
 coord1     | C         |     30001 | 10.138.32.232 | f              | f                |  1885696643
 coord2     | C         |     30002 | 10.138.32.233 | f              | f                | -1197102633
 datanode_1 | D         |     40001 | 10.138.32.80  | t              | f                |  -675012441
 datanode_2 | D         |     40102 | 10.138.32.79  | f              | f                | -1047623914
 
 
 alltrade=# select tableoid, cmin, cmax, xmin, xmax, ctid, oid, * from pgxc_node;
 tableoid | cmin | cmax |  xmin  | xmax | ctid  |  oid  | node_name  | node_type | node_port |  node_host   | nodeis_primary | nodeis_preferred |   node_id   
----------+------+------+--------+------+-------+-------+------------+-----------+-----------+--------------+----------------+------------------+-------------
     9015 |    0 |    0 | 104004 |    0 | (0,2) | 11819 | coord1     | C         |     30001 | 10.138.32.75 | f              | f                |  1885696643
     9015 |    0 |    0 | 104005 |    0 | (0,3) | 16384 | coord2     | C         |     30002 | 10.138.32.77 | f              | f                | -1197102633
     9015 |    0 |    0 | 104007 |    0 | (0,4) | 16385 | datanode_1 | D         |     40001 | 10.138.32.80 | t              | f                |  -675012441
     9015 |    0 |    0 | 104008 |    0 | (0,5) | 16386 | datanode_2 | D         |     40002 | 10.138.32.81 | f              | f                | -1047623914
(4 rows)


To Remove the database from pg_catalog 

delete from pg_catalog.pg_database where datname = 'alltrade_test';

delete from pg_catalog.pg_database where datname = 'alltrade_iot';

delete from pg_catalog.pg_database where datname = 'alltrade_prod';


EXECUTE DIRECT ON (datanode_1) 'delete from pg_catalog.pg_database where datname = ''alltrade_prod''';

EXECUTE DIRECT ON (datanode_1) 'delete from pg_catalog.pg_database where datname = ''alltrade_test''';

EXECUTE DIRECT ON (datanode_1) 'delete from pg_catalog.pg_database where datname = ''alltrade_iot''';


EXECUTE DIRECT ON (datanode_2) 'delete from pg_catalog.pg_database where datname = ''alltrade_prod''';

EXECUTE DIRECT ON (datanode_2) 'delete from pg_catalog.pg_database where datname = ''alltrade_test''';

EXECUTE DIRECT ON (datanode_2) 'delete from pg_catalog.pg_database where datname = ''alltrade_iot''';

========================================
Drop the database

SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'alltrade_test';

UPDATE pg_database SET datallowconn = 'false' WHERE datname = 'alltrade_test';

alter database alltrade_test connection limit 1;

SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'alltrade_iot';

UPDATE pg_database SET datallowconn = 'false' WHERE datname = 'alltrade_iot';

alter database alltrade_iot connection limit 1;

SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'alltrade_prod';

UPDATE pg_database SET datallowconn = 'false' WHERE datname = 'alltrade_prod';

alter database alltrade_prod connection limit 1;

DROP DATABASE alltrade_iot;
DROP DATABASE alltrade_prod;
DROP DATABASE  alltrade_test;

=====================================

CREATE USER admin_alltrade SUPERUSER LOGIN PASSWORD 'admin_alltrade';
CREATE USER toro SUPERUSER LOGIN PASSWORD 'toro';
CREATE USER serveradm SUPERUSER LOGIN PASSWORD 'serveradm';
CREATE USER ro_alltrade SUPERUSER LOGIN PASSWORD 'ro_alltrade';

================================
CREATE DATABASE "alltrade_prod"
  ENCODING 'UTF8'
  LC_COLLATE = 'en_US.UTF-8'
  LC_CTYPE = 'en_US.UTF-8';
  
CREATE DATABASE "alltrade_iot"
  ENCODING 'UTF8'
  LC_COLLATE = 'en_US.UTF-8'
  LC_CTYPE = 'en_US.UTF-8';
  
CREATE DATABASE "alltrade_test"
  ENCODING 'UTF8'
  LC_COLLATE = 'en_US.UTF-8'
  LC_CTYPE = 'en_US.UTF-8';  
  
=============================
deleting the user from pg_catalog
delete from pg_authid where rolname = 'admin_alltrade';  
====================================
error : postgres error invalid primary checkpoint record
solution : pg_resetxlog -f DATADIR 
=====================================
Redistribution of Data in postgresxl
The redistribution funcionality is still pretty basic, but what is simply does is:

-- fetch all the data of the table to be redistributed on Coordinator
		Data is store in the base directory in pgsql_tmp folder with some filename
-- Truncate the table
-- Update the catalogs to the new distribution type
-- Redistribute the data cached on Coordinator

ALTER TABLE with clauses DISTRIBUTE BY, ADD NODE, DELETE NODE, TO NODE or TO GROUP is used for data redistribution among nodes specific to Postgres-XL. Those clauses cannot be used with other commands.

Multiple redistribution scenarios are possible depending on modifications done:

Default redistribution:
This is the slowest scenario possible. It is done in 3 or 4 steps. Data is firstly saved on Coordinator by fetching all the data with COPY TO command. At this point all the tuples are saved using a tuple store. The amount of cache allowed for tuple store operation can be controlled with work_mem. Then the table is truncated on all the nodes. Then catalogs are updated. Finally data inside the tuple store is redistributed using an internal COPY FROM mechanism. REINDEX is issued if necessary. The overall performance of this scenario is close to the time necessary to run consecutively COPY TO and COPY FROM.

Redistribution from replicated to replicated table:
The node list of a table can have new nodes as well as removed nodes. If nodes are only removed, TRUNCATE is launched to remote nodes that are removed. If new nodes are added, then table data is fetched on the Coordinator with COPY TO and stored inside a tuple store controlled with work_mem, then data stored is only sent to the new nodes using COPY FROM with data stored inside the tuplestore. REINDEX is issued if necessary.

Redistribution from replicated to distributed table:
If the relation node list contains new nodes, the default redistribution mechanism is used. However, if the node list of relation after redistribution is included in node list of relation after redistribution, as all the tuples are already located on remote nodes, it is not necessary to fetch any data on Coordinator. Hence, DELETE is used to remove on remote nodes only the necessary tuples. This query selects tuples to remove with conditions based on the number of nodes in the node list of relations after redistribution, the HASH or MODULO value used for new distribution and the remote node itself where DELETE is launched.. REINDEX is issued if necessary.

Redistribution from distributed to replicated table:
In this case the default redistribution mechanism is used.
=====================================
ALTER table reference

https://www.postgres-xl.org/documentation/sql-altertable.html

